---
layout: article
title: KOVENS'19 - The German-focused NLP Conference
date: 2019-10-23 11:25:00  # if the publication date is in the future the article will be published on that future date
categories: [NLP, KOVENS, conference, data-challenge]
comments: false
share: true
image:
  teaser: 2019_10_23/konvens2019.png
  feature: 2019_10_23/erlangen_university_scaled.png
description: The KOVENS'19 conference on Natural Language Processing for German
usemathjax: false  # if you need math symbols turn this one
author: david_batista
---

KOVENS is a yearly held conference which gathers together the computer scientists
and computational linguists community working with the German language.

This year's edition of KOVENS was held in the city of Erlangen, Germany, at the
Friedrich Ebert University. The conference lasted for 4 days, being the first
reserved to tutorials and workshops and the following days to presentations and
poster sessions, and of course coffee breaks, which are essentially to keep the
mood and get to know each other.

## Workshop

<!-- Data Challenge and Participation -->

This year's workshop hold a data-challenge, GermEval, consisting of two shared
tasks, much inspired in the vein of [SemEval](https://www.wikiwand.com/en/SemEval)
but focusing on the German language NLP tasks. This year there were two tasks:

- [Shared Task on Hierarchical Classification of Blurbs](https://competitions.codalab.org/competitions/20139)
- [Shared Task on the Identification of Offensive Language](https://projects.fzai.h-da.de/iggsa)

The Comtravo data science team participated on the Hierarchical Classification
task. The challenge consisted on a hierarchical-document classification task where
the hierarchical structure of each document needs to be captured. The documents
were short descriptions of books and one needed to classify them into one of
several categories.

The task was further divided into two sub-tasks, one targeting only the first level
of the hierarchy and the second targeting the second and third levels. We explored
two different strategies.

<div style="width: 33%; height: 33%; display: block; margin-left: 2%; margin-right: 4%; float: left;">
    <img src="/images/2019_10_23/dsbatista_kovens19.jpg">
</div>

The first one was based on more classic machine learning approaches, a logistic
regression classifier with TF-IDF weighted vectors. The second approach was
based on Convolutional Neural Networks for sentence classification.

Our submissions achieved the 13th place out of 19 submissions for Sub-Task A and
the 11th place out of 19 submissions for Sub-Task B. You can read the [paper with description of our approach](https://www.inf.uni-hamburg.de/en/inst/ab/lt/resources/data/germeval-2019-hmc/paper-4.pdf) and the [code is also publicly available](https://github.com/davidsbatista/GermEval-2019-Task_1)

We had still many ideas worth exploring but time constrains we only submitted
baseline systems for other ideas worth exploring.

One curious aspect of this challenge was that both wining solutions used different
different approaches for the task, one based on state-of-the-art neural networks
for seq2seq tasks, and the other based on SVM and TF-IDF weighted vectors for
text representation.

You can read the papers of both best winners here:
 - [Multi-Label Multi-Class Hierarchical Classification using
Convolutional Seq2Seq](https://corpora.linguistik.uni-erlangen.de/data/konvens/proceedings/papers/germeval/Germeval_Task1_paper_2.pdf)
 - [TwistBytes - Hierarchical Classification at GermEval 2019: walking the fine line (of recall and precision) Fernando Benites](https://corpora.linguistik.uni-erlangen.de/data/konvens/proceedings/papers/germeval/Germeval_Task1_paper_6.pdf)


## Main Conference

After the workshop the following days were dedicated to several topics within
NLP applied to German. Having a mixed community of computer scientists and
computational linguists results in having a very diverse type of research work.

<!-- Interesting Papers/Posters -->



<!--
https://2019.konvens.org/program

BERT stuff

BERT for Named Entity Recognition in Contemporary and Historic German
Kai Labusch, Clemens Neudecker and David ZellhÃ¶fer

- Gregor Wiedemann, Avi Chawla, Steffen Remus and Chris Biemann. Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings.



Students workshop
=================

- Grasping the Nettle: Neural Entity Recognition for Scientific and Vernacular Plant Names

-->

